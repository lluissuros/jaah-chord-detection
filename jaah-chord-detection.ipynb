{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO remove\n",
    "#interesting code:\n",
    "#: https://github.com/reeanne/FinalProject/blob/cef6b45060ad9646f2be4de93c226aebeadec41b/essentia-master/src/examples/python/streaming_extractor/tonaldescriptors.py\n",
    "#https://github.com/LqNoob/Essentia/blob/7a70a25dd6668855b3677bd0cae0df190e319cbf/test/src/unittest/tonal/test_chordsdetection_streaming.py\n",
    "#âˆ«imple one https://github.com/mariogearth/ChordsDetectionPython/blob/b69e813bef92a361e7cad0a58bbd0f049b252914/old%20stuff/chords_test3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from collections import deque\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "%matplotlib inline\n",
    "\n",
    "import essentia, essentia.standard, essentia.streaming\n",
    "import essentia.standard as ess\n",
    "from essentia.standard import BeatTrackerMultiFeature\n",
    "from essentia.standard import ChordsDetectionBeats\n",
    "from essentia.streaming import *\n",
    "\n",
    "import mir_eval\n",
    "import seaborn as sns\n",
    "from pylab import savefig\n",
    "import glob\n",
    "from music21 import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "UTILS \n",
    "utils, inspired/copied from:\n",
    "  https://github.com/seffka/ACE2017/blob/master/essentia_chord_utils.py\n",
    "\n",
    "'''\n",
    "\n",
    "def tuning(infile):\n",
    "    hopSize = 2048\n",
    "    frameSize = 8192\n",
    "    loader = MonoLoader(filename=infile)\n",
    "    framecutter = FrameCutter(hopSize=hopSize, frameSize=frameSize)\n",
    "    windowing = Windowing(type=\"blackmanharris62\")\n",
    "    spectrum = Spectrum()\n",
    "    spectralpeaks = SpectralPeaks(orderBy=\"frequency\",\n",
    "                                  magnitudeThreshold=1e-05,\n",
    "                                  minFrequency=40,\n",
    "                                  maxFrequency=5000,\n",
    "                                  maxPeaks=10000)\n",
    "    tuning = TuningFrequency()\n",
    "    # use pool to store data\n",
    "    pool = essentia.Pool()\n",
    "    # connect algorithms together\n",
    "    loader.audio >> framecutter.signal\n",
    "    framecutter.frame >> windowing.frame >> spectrum.frame\n",
    "    spectrum.spectrum >> spectralpeaks.spectrum\n",
    "    spectralpeaks.magnitudes >> tuning.magnitudes\n",
    "    spectralpeaks.frequencies >> tuning.frequencies\n",
    "    tuning.tuningFrequency >> (pool, 'tonal.tuningFrequency')\n",
    "    tuning.tuningCents >> (pool, 'tonal.tuningCents')\n",
    "    # network is ready, run it\n",
    "    essentia.run(loader)\n",
    "    return np.average(pool['tonal.tuningFrequency'])\n",
    "\n",
    "class ChordSegment :\n",
    "    startTime = 0.0\n",
    "    endTime = 0.0\n",
    "    symbol = ''\n",
    "    def __init__(self, startTime, endTime, symbol):\n",
    "        self.startTime = startTime\n",
    "        self.endTime = endTime\n",
    "        self.symbol = symbol\n",
    "    def __repr__(self):\n",
    "        return str(self.startTime) + '\\t' + str(self.endTime) + '\\t' + self.symbol\n",
    "    \n",
    "def mergeSegments(chordSegments) :\n",
    "    if (len(chordSegments) < 2) :\n",
    "        return chordSegments\n",
    "    res = []\n",
    "    currentSegment = chordSegments[0]\n",
    "    for segment in chordSegments[1:] :\n",
    "        if (segment.symbol == currentSegment.symbol):\n",
    "            currentSegment.endTime = segment.endTime\n",
    "        else:\n",
    "            res.append(currentSegment)\n",
    "            currentSegment = segment\n",
    "    res.append(currentSegment)\n",
    "    return res\n",
    "\n",
    "def convertChordLabels(chordSegments) :\n",
    "    for segment in chordSegments :\n",
    "        segment.symbol = re.sub('m$', ':min', segment.symbol)\n",
    "    return chordSegments\n",
    "\n",
    "\n",
    "def toMirexLab(startTime, endTime, onsets, symbols, strengths) :\n",
    "    if (len(onsets) < len(symbols) or len(symbols) != len(strengths)) :\n",
    "        raise ValueError(\"inappropriate lists lengths\")\n",
    "    if (len(onsets) == len(symbols)) :\n",
    "        onsets = np.concatenate((onsets, [endTime]))\n",
    "    res = []\n",
    "    if (startTime < onsets[0]) :\n",
    "        res.append(ChordSegment(startTime, onsets[0], 'N'))\n",
    "    for i in range(len(symbols)) :\n",
    "        sym = symbols[i] if strengths[i] > 0 else 'N'\n",
    "        res.append(ChordSegment(onsets[i], onsets[i+1], sym))\n",
    "    if (res[-1].endTime < endTime) :\n",
    "        res.append(ChordSegment(res[-1].endTime, endTime, 'N'))\n",
    "    return convertChordLabels(mergeSegments(res))\n",
    "\n",
    "\n",
    "def processFiles(inputDir, outputDir, processFunction) :\n",
    "    for file in [f for f in os.listdir(inputDir) if os.path.isfile(os.path.join(inputDir, f))] :\n",
    "        name, ext = os.path.splitext(file)\n",
    "        processFunction(os.path.join(inputDir, file), os.path.join(outputDir, name + '.lab'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Compute Chords by Frames in Essentia \n",
    "utils, inspired/copied from:\n",
    "  https://github.com/seffka/ACE2017/blob/master/essentia_chord_utils.py\n",
    "\n",
    "'''\n",
    "\n",
    "def computeChordsByFrames(filename, outfile, frameSize=4096, hopSize=2048, tuningFrequency=440.0):\n",
    "\n",
    "    #TODO:check pools https://essentia.upf.edu/documentation/essentia_python_tutorial.html \n",
    "\n",
    "    pool = essentia.Pool()\n",
    "    loader = essentia.streaming.MonoLoader(filename=filename)\n",
    "    \n",
    "    #get the frames and compute chord detection\n",
    "    fc = FrameCutter(frameSize=frameSize,\n",
    "                     hopSize=hopSize,\n",
    "                     silentFrames='noise')\n",
    "\n",
    "    w = Windowing(type='blackmanharris62')\n",
    "    spec = Spectrum()\n",
    "    spectralpeaks = SpectralPeaks(orderBy=\"magnitude\",\n",
    "                                      magnitudeThreshold=1e-05,\n",
    "                                      minFrequency=40,\n",
    "                                      maxFrequency=5000,\n",
    "                                      maxPeaks=10000)\n",
    "    \n",
    "    #TODO learn: https://essentia.upf.edu/documentation/reference/std_HPCP.html\n",
    "    hpcp = HPCP(\n",
    "        size=12,\n",
    "        referenceFrequency = tuningFrequency,\n",
    "        harmonics = 8,\n",
    "        bandPreset = True,\n",
    "        minFrequency = 40.0,\n",
    "        maxFrequency = 5000.0,\n",
    "        bandSplitFrequency = 250.0,\n",
    "        weightType = \"cosine\",\n",
    "        nonLinear = False,\n",
    "        windowSize = 1.0,\n",
    "        normalized='unitMax')\n",
    "    \n",
    "    #TODO: check parameters https://essentia.upf.edu/documentation/reference/std_ChordsDetection.html\n",
    "    chords = ChordsDetection()\n",
    "    chords_desc = ChordsDescriptors()\n",
    "\n",
    "\n",
    "    # connect algorithms together\n",
    "    loader.audio >> fc.signal\n",
    "    fc.frame >> w.frame >> spec.frame\n",
    "    spec.spectrum >> spectralpeaks.spectrum\n",
    "    spec.spectrum >> (pool, 'spectrum.magnitude') #mine\n",
    "    spectralpeaks.frequencies >> hpcp.frequencies\n",
    "    spectralpeaks.magnitudes >> hpcp.magnitudes\n",
    "    hpcp.hpcp >> (pool, 'chroma.hpcp')  #mine\n",
    "    hpcp.hpcp >> chords.pcp\n",
    "    chords.chords >> (pool, 'chords.chords')\n",
    "    chords.strength >> (pool, 'chords.strength')\n",
    "\n",
    "    essentia.run(loader)\n",
    "\n",
    "    audio = essentia.standard.MonoLoader(filename = filename)()\n",
    "    endTime = len(audio) / 44100.0\n",
    "    stamps = np.arange(0, endTime, float(hopSize/44100.0))\n",
    "    stamps = np.array([round(stamp,2) for stamp in stamps]) #2 decimals\n",
    "\n",
    "    # workaround for Essentia behaviour I don't quite undestand: https://github.com/seffka/ACE2017/blob/467068d9667de43de8b8b8396e620d9e62a0d85c/essentia_chords.py\n",
    "    syms = list(pool['chords.chords'][:-1])\n",
    "    strengths = list(pool['chords.strength'][:-1])\n",
    "    segments = toMirexLab(0.0, endTime, stamps, syms, strengths)\n",
    "    with open(outfile, 'w') as content_file:\n",
    "        for s in segments:\n",
    "            content_file.write(str(s) + '\\n')\n",
    "    #print(\"\\n\", outfile, \" was written\")\n",
    "\n",
    "    \n",
    "    spectrum= pool['spectrum.magnitude']\n",
    "    chroma= pool['chroma.hpcp']\n",
    "    chords= pool['chords.chords']\n",
    "    chords_strength= pool['chords.strength']\n",
    "    \n",
    "    return spectrum, chroma, chords, chords_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeChordsByBeats(filename, outfile, hopSize=4096, frameSize=8192, tuningFrequency=440.0):\n",
    "    \n",
    "    # use pool to store data\n",
    "    pool = essentia.Pool()\n",
    "    # initialize algorithms we will use\n",
    "    loader = MonoLoader(filename=filename)\n",
    "    framecutter = FrameCutter(hopSize=hopSize, frameSize=frameSize)\n",
    "    windowing = Windowing(type=\"blackmanharris62\")\n",
    "    spectrum = Spectrum()\n",
    "    spectralpeaks = SpectralPeaks(orderBy=\"magnitude\",\n",
    "                                  magnitudeThreshold=1e-05,\n",
    "                                  minFrequency=40,\n",
    "                                  maxFrequency=5000,\n",
    "                                  maxPeaks=10000)\n",
    "    hpcp = HPCP(size=12,\n",
    "                referenceFrequency = tuningFrequency,\n",
    "                harmonics = 8,\n",
    "                bandPreset = True,\n",
    "                minFrequency = 40.0,\n",
    "                maxFrequency = 5000.0,\n",
    "                bandSplitFrequency = 500.0,\n",
    "                weightType = \"cosine\",\n",
    "                nonLinear = True,\n",
    "                windowSize = 1.0)\n",
    "\n",
    "    # connect algorithms together\n",
    "    loader.audio >> framecutter.signal\n",
    "    framecutter.frame >> windowing.frame >> spectrum.frame\n",
    "    spectrum.spectrum >> spectralpeaks.spectrum\n",
    "    spectralpeaks.magnitudes >> hpcp.magnitudes\n",
    "    spectralpeaks.frequencies >> hpcp.frequencies\n",
    "    hpcp.hpcp >> (pool, 'chroma.hpcp')\n",
    "\n",
    "    essentia.run(loader)\n",
    "    \n",
    "    #print('Loading audio file...', filename)\n",
    "    audio = ess.MonoLoader(filename = filename)()\n",
    "    bt = ess.BeatTrackerMultiFeature()\n",
    "    beats, confidence = bt(audio)\n",
    "    beats = np.array([round(beat,2) for beat in beats])\n",
    "    \n",
    "    #ticks = beats[::4] # TODO: should we take each 4 beats??\n",
    "    #print(\"number of beats\", len(beats))\n",
    "\n",
    "    computeChordsByBeats = ChordsDetectionBeats(hopSize=hopSize)\n",
    "    chords, strengths = computeChordsByBeats(pool['chroma.hpcp'], beats)\n",
    "    \n",
    "    segments = toMirexLab(0.0, len(audio) / 44100.0, beats, chords, strengths)\n",
    "    with open(outfile, 'w') as content_file:\n",
    "        for s in segments:\n",
    "            content_file.write(str(s) + '\\n')\n",
    "    #print(\"\\n\", outfile, \" was written\")\n",
    "    \n",
    "    \n",
    "    return chords, strengths, beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateTriads(estimate_file, reference_file):\n",
    "    '''\n",
    "    expects .lab files\n",
    "    performs mir_eval on triads\n",
    "    return an object called result '''\n",
    "    (ref_intervals, ref_labels) = mir_eval.io.load_labeled_intervals(reference_file)\n",
    "    (est_intervals, est_labels) = mir_eval.io.load_labeled_intervals(estimate_file)\n",
    "\n",
    "    est_intervals, est_labels = mir_eval.util.adjust_intervals(\n",
    "        est_intervals, est_labels, ref_intervals.min(),\n",
    "        ref_intervals.max(), mir_eval.chord.NO_CHORD,\n",
    "        mir_eval.chord.NO_CHORD)\n",
    "\n",
    "    (intervals,\n",
    "     ref_labels,\n",
    "     est_labels) = mir_eval.util.merge_labeled_intervals(\n",
    "        ref_intervals, ref_labels, est_intervals, est_labels)\n",
    "\n",
    "    durations = mir_eval.util.intervals_to_durations(intervals)\n",
    "    comparisons = mir_eval.chord.triads(ref_labels, est_labels)\n",
    "    score = mir_eval.chord.weighted_accuracy(comparisons, durations)\n",
    "    \n",
    "    #create a result object and save all that might be handy\n",
    "    class Object(object):\n",
    "        pass\n",
    "    \n",
    "    result = Object()\n",
    "    result.durations = durations\n",
    "    result.comparisons = comparisons\n",
    "    result.score = score\n",
    "    result.intervals = intervals\n",
    "    result.ref_labels = ref_labels\n",
    "    result.est_labels = est_labels\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_track(track_path):\n",
    "    '''\n",
    "    Process the track with chord by frames and by beats, perform mir_eval and return evaluation for both methods\n",
    "    '''\n",
    "    references_path = './ref_labs/'\n",
    "    estimated_chord_beat_path = './estimated_chordBeat_labs/'\n",
    "    estimated_chord_frame_path = './estimated_chordFrame_labs/'\n",
    "    \n",
    "    #get the .lab filepath\n",
    "    track_name = os.path.basename(track_path)\n",
    "    lab_name = os.path.splitext(track_name)[0] + '.lab'\n",
    "\n",
    "    #filenames\n",
    "    reference_lab = references_path + lab_name\n",
    "    estimated_chordBeat_lab = estimated_chord_beat_path + lab_name\n",
    "    estimated_chordFrame_lab = estimated_chord_frame_path + lab_name\n",
    "\n",
    "    #create lab files\n",
    "    song_tuning = tuning(track_path)\n",
    "    computeChordsByBeats(track_path, estimated_chordBeat_lab, tuningFrequency=song_tuning)\n",
    "    computeChordsByFrames(track_path, estimated_chordFrame_lab, tuningFrequency=song_tuning)\n",
    "\n",
    "    #evaluate chord By Beat\n",
    "    beat_mir_eval_result = evaluateTriads(estimated_chordBeat_lab, reference_lab)\n",
    "\n",
    "    #evaluate chords By Frame\n",
    "    frame_mir_eval_result = evaluateTriads(estimated_chordFrame_lab, reference_lab)\n",
    "    \n",
    "    return beat_mir_eval_result, frame_mir_eval_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Covert dictionary into dataframes\n",
    "def convert_dict(dict_comparelabels, dict_foreachchord):\n",
    "    #pd_rank: count and rank mistakes, the first line is the most common mistake\n",
    "    pd_rank = pd.DataFrame.from_dict(dict_comparelabels, orient = 'index')\n",
    "    pd_rank = pd_rank.reset_index(drop = False)\n",
    "    pd_rank.columns = ['chord pairs', 'count']\n",
    "    pd_rank = pd_rank.sort_values(by=['count'], ascending=False)\n",
    "    \n",
    "    #pd_compareeach: count and rank mistakes for every single chord\n",
    "    pd_compareeach = pd.DataFrame.from_dict(dict_foreachchord, orient = 'index')\n",
    "\n",
    "    return pd_rank, pd_compareeach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a heatmap for mistakes the algorithm has made\n",
    "def makebigheatmap(pd_makeheatmap):\n",
    "    plt.subplots(figsize=(12,60))\n",
    "    svm = sns.heatmap(pd_makeheatmap, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "    #print(\"x axis is estimated chords, y axis is the ground truth\")\n",
    "    figure = svm.get_figure()\n",
    "    plt.show()\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a heatmap for mistakes the algorithm has made\n",
    "def makesmallheatmap(pd_makeheatmap):\n",
    "    #plt.subplots(figsize=(5,10))\n",
    "    svm = sns.heatmap(pd_makeheatmap, annot=True, fmt=\".0f\", cmap=\"YlGnBu\")\n",
    "    #print(\"x axis is estimated chords, y axis is the ground truth\")\n",
    "    figure = svm.get_figure()\n",
    "    plt.show()\n",
    "    return figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count label pairs(the ones that's wrongly detected, and sort them\n",
    "#dict_comparelabels: overall; dict_foreachchord: count mistakes for each chord\n",
    "def Count_for_song(ref_labels, comparisons, est_labels):\n",
    "\n",
    "    dict_comparelabels = dict()\n",
    "    dict_foreachchord = dict()\n",
    "\n",
    "    for i in range(len(ref_labels)):\n",
    "        #If there is no mistake, continue\n",
    "        if comparisons[i] == 1: \n",
    "            continue\n",
    "        #Count overall mistakes\n",
    "        temp = [ref_labels[i], est_labels[i]] #[ground truth, estimated]\n",
    "        tempstr = str(temp)\n",
    "        if tempstr not in dict_comparelabels:\n",
    "            dict_comparelabels[tempstr] = 0\n",
    "        dict_comparelabels[tempstr]+=1\n",
    "\n",
    "        #Count for each chord\n",
    "        if ref_labels[i] not in dict_foreachchord:\n",
    "            dict_foreachchord[ref_labels[i]] = dict()\n",
    "        if est_labels[i] not in dict_foreachchord[ref_labels[i]]:\n",
    "            dict_foreachchord[ref_labels[i]][est_labels[i]] = 0\n",
    "        dict_foreachchord[ref_labels[i]][est_labels[i]]+=1\n",
    "        #Convert dictionaries into a dataframe\n",
    "        most_common_errors, df_result = convert_dict(dict_comparelabels, dict_foreachchord)\n",
    "    #Return the result(a big dataframe for a song)\n",
    "    return df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will find the most common mistakes for each chord(rank wrongly estimated chords by occurrence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mistakes_each_chord(pd_findmistake):\n",
    "    temprow_names = []\n",
    "    temprow_mistakes = []\n",
    "    for rownum in range(0, len(pd_findmistake)):\n",
    "        temprow = pd_findmistake.iloc[rownum]\n",
    "        temprow = temprow.sort_values(ascending=False)\n",
    "        temprow = temprow.dropna()\n",
    "        #temprow.name is the current ground truth chord\n",
    "        #temprow.index.values is the estimated chords\n",
    "        #if you print temprow, it will print out the occurrence too\n",
    "        temprow_names.append(temprow.name)\n",
    "        temprow_mistakes.append(temprow.index.values)\n",
    "        #print(temprow.name)\n",
    "        #print(temprow.index.values)\n",
    "    return temprow_names, temprow_mistakes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def One_song_analysis(pd_beat_single, pd_frame_single):\n",
    "    \n",
    "    print(\"Chosen_track_heatmap_by_beat\")\n",
    "    fig_beat_single = makesmallheatmap(pd_beat_single)\n",
    "    pngname = 'chosen_song_beat.png'\n",
    "    fig_beat_single.savefig(pngname, dpi=400)\n",
    "        \n",
    "    chordnames_beat, mistakes_beat = find_mistakes_each_chord(pd_beat_single)\n",
    "    #Showing the most common mistakes for each chord\n",
    "    for index_i in range(len(chordnames_beat)):\n",
    "        print(chordnames_beat[index_i], mistakes_beat[index_i])\n",
    "\n",
    "    print(\"Chosen_track_heatmap_by_frame\")\n",
    "    fig_frame_single = makesmallheatmap(pd_frame_single)\n",
    "    pngname = 'chosen_song_frame.png'\n",
    "    fig_frame_single.savefig(pngname, dpi=400)\n",
    "\n",
    "    chordnames_frame, mistakes_frame = find_mistakes_each_chord(pd_frame_single)\n",
    "    for index_i in range(len(chordnames_frame)):\n",
    "        print(chordnames_frame[index_i], mistakes_frame[index_i])\n",
    "    \n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#TODO: KeyError: '7/3', if the function can't calculate distance for given chord pairs, print a message.\n",
    "\n",
    "def compute_chords_note_difference(truth_chord, est_chord):\n",
    "    '''\n",
    "    Compute how similar are the mistakes: do the mistaken chords share a lot of notes,\n",
    "    or are they very different between them?\n",
    "     Note: we are aware that this might be a naive approach, but we think it is relevant to check if chords \n",
    "     that are mistaken often share many notes.\n",
    "    '''\n",
    "    if(truth_chord == 'N' or est_chord =='N'):\n",
    "        print(\"Can't compute distance for N\")    \n",
    "        return None\n",
    "\n",
    "    chord_qualities = {\n",
    "        #           1     2     3     4  5     6     7        \n",
    "        'maj':     [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],        \n",
    "        'min':     [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        'aug':     [1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
    "        'dim':     [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
    "        'sus4':    [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0],\n",
    "        'sus2':    [1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        '7':       [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        'maj7':    [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    "        'min7':    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "        'minmaj7': [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
    "        'maj6':    [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0],\n",
    "        'min6':    [1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0],\n",
    "        'dim7':    [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0],\n",
    "        'hdim7':   [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0],\n",
    "        'maj9':    [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    "        'min9':    [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "        '9':       [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        'b9':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        '#9':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        'min11':   [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "        '11':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        '#11':     [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        'maj13':   [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1],\n",
    "        'min13':   [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
    "        '13':      [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        'b13':     [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0],\n",
    "        '1':       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "        '5':       [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
    "        '':        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
    "    \n",
    "    \n",
    "    def create_custom_disposition(chord):\n",
    "        '''\n",
    "        creates a custom disposition for a chord string expressed like (b3,5,7,9) or (b3,5,7)/5\n",
    "        '''\n",
    "        disposition = [1,0,0,0,0,0,0,0,0,0,0,0] #initial disposition\n",
    "        degrees_to_disposition_index = {2: 2, 3: 4, 4: 6, 5: 7, 6: 9, 7: 11, 9: 2, 10: 4, 11: 6, 13: 9} #what index is each degree\n",
    "        degrees = chord.replace('(', '' ).replace(')', '').split(',')\n",
    "        \n",
    "        for degree in degrees:\n",
    "            accidental = 0\n",
    "            if 'b' in degree: #todo dism\n",
    "                accidental = -1\n",
    "            if '#' in degree: #todo aug\n",
    "                accidental = 1\n",
    "            degree_int = int(re.findall('\\d', degree)[0]) #get the integer part\n",
    "            degree_index = degrees_to_disposition_index[degree_int] +  accidental #get the index and sum accidental\n",
    "            disposition[degree_index] = 1         \n",
    "        return disposition\n",
    "\n",
    "\n",
    "    def get_root(chord):\n",
    "        '''returns the root of the chord'''\n",
    "        if ':' in chord: \n",
    "            return chord[0: chord.index(':')]\n",
    "        elif '/' in chord:\n",
    "            return chord[0: chord.index('/')]\n",
    "        return chord\n",
    "\n",
    "\n",
    "    def get_chord_type(chord):\n",
    "        '''returns the chord type'''\n",
    "        try: \n",
    "            chord.index(':')       \n",
    "            return chord[chord.index(':')+1:]\n",
    "        except: \n",
    "            return 'maj'\n",
    "\n",
    "\n",
    "    def get_notes_disposition(chord):\n",
    "        '''\n",
    "        will return a 12-note array with the note disposition for a chord\n",
    "        example: for a '7' return [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
    "        '''\n",
    "        chord_type = get_chord_type(chord)\n",
    "        if chord_type in chord_qualities:   \n",
    "            return chord_qualities[chord_type]\n",
    "        return create_custom_disposition(chord_type)\n",
    "\n",
    "\n",
    "    def transpose_disposition(dispostion, interval_semitones):\n",
    "        '''will tranpose(shift) the given disposition the given interval semitones'''    \n",
    "        items = deque(dispostion)\n",
    "        items.rotate(interval_semitones)\n",
    "        return list(items)\n",
    "\n",
    "\n",
    "    def difference(li1, li2):\n",
    "        '''counts the different items in two list of the same size'''\n",
    "        diff_count = 0\n",
    "        for i in range(len(li1)):\n",
    "            if li1[i] != li2[i]: diff_count +=1\n",
    "        return diff_count\n",
    "\n",
    "    #compute note disposition for each chord:\n",
    "    truth_disposition = get_notes_disposition(truth_chord)\n",
    "    estimated_disposition = get_notes_disposition(est_chord)\n",
    "\n",
    "\n",
    "    #compute distance in semitones between truth and estimation\n",
    "    truth_root = note.Note(get_root(truth_chord))\n",
    "    est_root = note.Note(get_root(est_chord))\n",
    "    interval_semitones = interval.notesToChromatic(truth_root, est_root).semitones\n",
    "\n",
    "    #we need to transpose the estimated chord to the same root as the ground truth:\n",
    "    transposed_estimated_disposition = transpose_disposition(estimated_disposition, interval_semitones)\n",
    "\n",
    "    #now can compare the note disposition between both and count how many different notes\n",
    "    different_notes = difference(truth_disposition, transposed_estimated_disposition)\n",
    "    return different_notes\n",
    "    \n",
    "    \n",
    "#test\n",
    "print(compute_chords_note_difference('Eb:7', 'Ab/3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Persisting dictionary as json utilities: \n",
    "this will allow to save the ongoing results into jsons, and later we can check if a song was already analised \n",
    "so we don't analise it again. Like this we can run the code in different sessions!\n",
    "'''\n",
    "\n",
    "def persist_dict_into_json(dictionary, json_name):\n",
    "    file = open(json_name+\".json\", \"w\")\n",
    "    file.write(json.dumps(dictionary, indent=4, sort_keys=True)) #make it pretty-printed and sorted\n",
    "    file.close()\n",
    "    \n",
    "def load_json_as_dict(json_name):\n",
    "    file = open(json_name+\".json\", \"r\")\n",
    "    data = json.load(file)\n",
    "    file.close()\n",
    "    return data\n",
    "\n",
    "def persist_all_dictionaries():\n",
    "    persist_dict_into_json(global_beats_mistakes_count, persist_path+\"global_beats_mistakes_count\")\n",
    "    persist_dict_into_json(global_beats_mistakes_by_chord, persist_path+\"global_beats_mistakes_by_chord\")\n",
    "    persist_dict_into_json(global_beats_scores, persist_path+\"global_beats_scores\")\n",
    "    persist_dict_into_json(global_frames_mistakes_count, persist_path+\"global_frames_mistakes_count\")\n",
    "    persist_dict_into_json(global_frames_mistakes_by_chord, persist_path+\"global_frames_mistakes_by_chord\")\n",
    "    persist_dict_into_json(global_frames_scores, persist_path+\"global_frames_scores\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed audio file:  1 / 5 \t ./audios_same_name/parkers_mood.flac\n",
      "Already processed audio file:  2 / 5 \t ./audios_same_name/grandpas_spells.flac\n",
      "Already processed audio file:  3 / 5 \t ./audios_same_name/evidence.flac\n",
      "Processing audio file:  4 / 5 \t ./audios_same_name/four_or_five_times.flac\n",
      "Processing audio file:  5 / 5 \t ./audios_same_name/for_dancers_only.flac\n"
     ]
    }
   ],
   "source": [
    "#MAIN FUNCTION\n",
    "audios_path = './audios_same_name/'\n",
    "persist_path = './estimation_jsons/'\n",
    "\n",
    "#get all audio track paths\n",
    "all_audio_tracks = glob.glob(audios_path + '*.flac', recursive = True)\n",
    "num_tracks = len(all_audio_tracks)\n",
    "\n",
    "#dictionaries were we will store the results for each song:\n",
    "global_beats_mistakes_count = dict()\n",
    "global_beats_mistakes_by_chord = dict()\n",
    "global_beats_scores = dict()\n",
    "global_frames_mistakes_count = dict()\n",
    "global_frames_mistakes_by_chord = dict()\n",
    "global_frames_scores = dict()\n",
    "\n",
    "\n",
    "    \n",
    "def create_mistakes_count(evaluation_result): \n",
    "    '''\n",
    "    receives an evaluation result and creates a mistakes_count dictionary.\n",
    "\n",
    "    *example mistakes_count: \n",
    "    {\n",
    "    \"['A:dim7', 'C:min']\": 2,\n",
    "     \"['A:dim7', 'D#']\"   : 3\n",
    "     }\n",
    "    \n",
    "    '''\n",
    "    mistakes_count = dict()\n",
    "    zipped = zip(\n",
    "        evaluation_result.ref_labels, #ground truth\n",
    "        evaluation_result.est_labels, #chord estimation results\n",
    "        evaluation_result.comparisons) \n",
    "    \n",
    "    for reference, estimation, comparison in zipped:     \n",
    "        if comparison == 1: #If there was no mistake, continue\n",
    "            continue       \n",
    "        #Count overall mistakes    \n",
    "        mistake_key = str([reference, estimation]) #dictionary key as 'truthChord_estimatedChord'\n",
    "        if mistake_key not in mistakes_count:\n",
    "            mistakes_count[mistake_key] = 0\n",
    "        mistakes_count[mistake_key]+=1        \n",
    "    return mistakes_count\n",
    "\n",
    "\n",
    "def create_mistakes_by_chord(evaluation_result): \n",
    "    '''\n",
    "    receives an evaluation result and creates a mistakes_count dictionary and a mistakes_by_chord dictionary.\n",
    "\n",
    "    *example mistakes_by_chord:\n",
    "     {\n",
    "     'Ab:7' : {'C#': 3, 'D#:min': 1, 'F:min': 1},\n",
    "     'Ab:min': {'C#:min': 1, 'G#': 3}\n",
    "     }\n",
    "    \n",
    "    '''\n",
    "    mistakes_by_chord = dict() \n",
    "    zipped = zip(\n",
    "        evaluation_result.ref_labels, #ground truth\n",
    "        evaluation_result.est_labels, #chord estimation results\n",
    "        evaluation_result.comparisons)\n",
    "    \n",
    "    for reference, estimation, comparison in zipped:    \n",
    "        if comparison == 1: #If there was no mistake, continue\n",
    "            continue\n",
    "        #Count for each chord\n",
    "        if reference not in mistakes_by_chord:\n",
    "            mistakes_by_chord[reference] = dict()\n",
    "        if estimation not in mistakes_by_chord[reference]:\n",
    "            mistakes_by_chord[reference][estimation] = 0\n",
    "        mistakes_by_chord[reference][estimation]+=1   \n",
    "    return mistakes_by_chord\n",
    "\n",
    "\n",
    "def get_track_name(track_path):\n",
    "    return os.path.basename(track_path)\n",
    "\n",
    "\n",
    "def evaluate_tracks_and_fill_global_dictionary(tracks):\n",
    "    '''will evaluate the tracks in the given list, and fill the dictionaries with information for next analsis'''\n",
    "    for index, track in enumerate(tracks):\n",
    "        #first,we check if a track was already processed (we need to check one of the dictionaries)\n",
    "        persistedData = load_json_as_dict(persist_path+\"global_frames_scores\")\n",
    "        if(get_track_name(track) in persistedData):\n",
    "            print ('Already processed audio file: ', index+1, '/', len(tracks), '\\t', track)\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            beat_mir_eval_result, frame_mir_eval_result = evaluate_track(track)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(track, ' \\n\\n got an exception during analisis or mir_eval: ', e)\n",
    "            continue\n",
    "\n",
    "        print ('Processing audio file: ', index+1, '/', len(tracks), '\\t', track)\n",
    "\n",
    "        key = get_track_name(track) # the key is the name of the file\n",
    "\n",
    "        #create dictionaries for beats\n",
    "        global_beats_mistakes_count[key] = create_mistakes_count(beat_mir_eval_result)\n",
    "        global_beats_mistakes_by_chord[key] = create_mistakes_by_chord(beat_mir_eval_result)\n",
    "        global_beats_scores[key] = beat_mir_eval_result.score\n",
    "        #create dictionaries for frames    \n",
    "        global_frames_mistakes_count[key] = create_mistakes_count(frame_mir_eval_result)\n",
    "        global_frames_mistakes_by_chord[key] = create_mistakes_by_chord(frame_mir_eval_result)\n",
    "        global_frames_scores[key] = frame_mir_eval_result.score\n",
    "        #save results on disk\n",
    "        persist_all_dictionaries()\n",
    "    \n",
    "    \n",
    "#finally, we call the evaluation:\n",
    "all_audio_tracks[:5]\n",
    "evaluate_tracks_and_fill_global_dictionary(all_audio_tracks[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'four_or_five_times.flac'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e675a760f483>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mdict_comparelabels_beat_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_aggregated_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_audio_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_beats_mistakes_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mdict_comparelabels_frame_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_aggregated_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_audio_tracks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_frames_mistakes_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-e675a760f483>\u001b[0m in \u001b[0;36mcreate_aggregated_dict\u001b[0;34m(tracks, mistake_count_dict)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtracks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtrackname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_track_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmistake\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmistake_count_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrackname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmistake\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maggregated_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0maggregated_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmistake\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmistake_count_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrackname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmistake\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'four_or_five_times.flac'"
     ]
    }
   ],
   "source": [
    "#compute aggregation for a number of tracks, could be a list by genres, or like in this case, for all the complete dataset\n",
    "\n",
    "def create_aggregated_dict(tracks, mistake_count_dict):\n",
    "    '''\n",
    "    Will return a dictionary with all mistakes for the requested tracks aggregated.\n",
    "    Expects a list of tracks and a dictionary where the keys are track names, and values are mistake_count dictionaries\n",
    "    '''\n",
    "    aggregated_dict = dict()\n",
    "    for track in tracks:\n",
    "        trackname = get_track_name(track)\n",
    "        for mistake in mistake_count_dict[trackname]:\n",
    "            if mistake not in aggregated_dict: \n",
    "                aggregated_dict[mistake] = mistake_count_dict[trackname][mistake]\n",
    "            else: aggregated_dict[mistake] += mistake_count_dict[trackname][mistake]       \n",
    "    return aggregated_dict\n",
    "\n",
    "\n",
    "def create_aggregated_by_chord_dict(tracks, mistake_by_chord_dict):\n",
    "    '''\n",
    "    Will return a dictionary with all mistakes for the requested tracks aggregated.\n",
    "    Expects a list of tracks and a dictionary where the keys are track names, and values are mistake_count dictionaries\n",
    "    '''\n",
    "    aggregated_dict = dict()\n",
    "    for track in tracks:\n",
    "        trackname = get_track_name(track)\n",
    "        for chord in mistake_by_chord_dict[trackname]:\n",
    "            if chord not in aggregated_dict: \n",
    "                aggregated_dict[chord] = mistake_by_chord_dict[trackname][chord]   \n",
    "            else:\n",
    "                #we need to update the chord dictionary:\n",
    "                for mistake_chord in mistake_by_chord_dict[trackname][chord]:\n",
    "                    mistake_chord_val = mistake_by_chord_dict[trackname][chord][mistake_chord]\n",
    "                    if mistake_chord not in aggregated_dict[chord]:\n",
    "                        aggregated_dict[chord][mistake_chord] = mistake_chord_val\n",
    "                    else:\n",
    "                         aggregated_dict[chord][mistake_chord] += mistake_chord_val\n",
    "    return aggregated_dict\n",
    "\n",
    "#load and create aggregation for mistakes count dictionary:\n",
    "global_beats_mistakes_count = load_json_as_dict(persist_path+\"global_beats_mistakes_count\")\n",
    "global_frames_mistakes_count = load_json_as_dict(persist_path+\"global_frames_mistakes_count\")\n",
    "dict_comparelabels_beat_all = create_aggregated_dict(all_audio_tracks, global_beats_mistakes_count)\n",
    "dict_comparelabels_frame_all = create_aggregated_dict(all_audio_tracks, global_frames_mistakes_count)\n",
    "\n",
    "#load and create aggregation for mistakes by chord  dictionary:\n",
    "global_beats_mistakes_by_chord = load_json_as_dict(persist_path+\"global_beats_mistakes_by_chord\")\n",
    "global_frames_mistakes_by_chord = load_json_as_dict(persist_path+\"global_frames_mistakes_by_chord\")\n",
    "dict_foreachchord_beat_all = create_aggregated_by_chord_dict(all_audio_tracks,global_beats_mistakes_by_chord)\n",
    "dict_foreachchord_frame_all = create_aggregated_by_chord_dict(all_audio_tracks, global_frames_mistakes_by_chord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "\n",
    "test ={\n",
    "    'these_foolish_things.flac': {\n",
    "        'A:dim7': {\n",
    "            'A': 3,\n",
    "            'A#': 3,\n",
    "            'C:min': 2\n",
    "        }},\n",
    "       'maple_leaf_rag(hyman).flac': {\n",
    "           'A:dim7': {\n",
    "               'A': 3,\n",
    "               'A#': 3,\n",
    "               'C:min': 2},\n",
    "           'B:dim7': {\n",
    "               'A': 1,\n",
    "               'A#': 1,\n",
    "               'C:min': 1},\n",
    "       }}\n",
    "\n",
    "create_aggregated_by_chord_dict(all_audio_tracks, test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compute and print mean scores for both frames and beats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print mean scores for score_dictionaries\n",
    "def compute_score_mean(score_dict):\n",
    "    '''compute overall scores for a given score dictionary'''\n",
    "    if len(score_dict) == 0: return None\n",
    "    aggregated_score = 0\n",
    "    for key in score_dict:\n",
    "        aggregated_score += score_dict[key]\n",
    "    return aggregated_score/len(score_dict)\n",
    "\n",
    "print(\"Overall accuracy of chord detection by beat: \", compute_score_mean(global_beats_scores))\n",
    "print(\"Overall accuracy of chord detection by frame: \", compute_score_mean(global_frames_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall top 20 errors for algorithm by beat\n",
    "rank_beat, df_result_beat = convert_dict(dict_comparelabels_beat_all, dict_foreachchord_beat_all)\n",
    "\n",
    "#Save top 20 in csv file\n",
    "rank_beat = rank_beat.iloc[:20]\n",
    "rank_beat.to_csv(r'Top_errors_overall_beat.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_beat = makebigheatmap(df_result_beat)\n",
    "figure_beat.savefig('heatmap_beat.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chordnames_beat_all, mistakes_beat_all = find_mistakes_each_chord(df_result_beat)\n",
    "with open('Top_errors_for_each_chord_beat.txt', 'w') as outfile:\n",
    "    for j in range(len(chordnames_beat_all)):\n",
    "        ##Output as json format\n",
    "        #json.dump(chordnames_beat_all[j], outfile)\n",
    "        #json.dump(str(mistakes_beat_all[j]), outfile)\n",
    "        ##Output as txt format\n",
    "        outfile.write(chordnames_beat_all[j]+'\\n')\n",
    "        outfile.write(str(mistakes_beat_all[j])+'\\n')\n",
    "        print(chordnames_beat_all[j], mistakes_beat_all[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze chord detection algorithm by frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall top 20 errors for algorithm by frame\n",
    "rank_frame, df_result_frame = convert_dict(dict_comparelabels_frame_all, dict_foreachchord_frame_all)\n",
    "\n",
    "#Save top 20 in csv file\n",
    "rank_frame = rank_frame.iloc[:20]\n",
    "rank_frame.to_csv(r'Top_errors_overall_frame.csv')\n",
    "\n",
    "##Save in txt file\n",
    "#with open('Top_errors_overall_frame.txt', 'w') as outfile:\n",
    "#    for rownum in range(0, 21):\n",
    "#        temprow = rank_frame.iloc[rownum]\n",
    "#        outfile.write(temprow[\"chord pairs\"])\n",
    "#        outfile.write(str(temprow[\"count\"])+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_frame = makebigheatmap(df_result_frame)\n",
    "figure_frame.savefig('heatmap_frame.png', dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chordnames_frame_all, mistakes_frame_all = find_mistakes_each_chord(df_result_frame)\n",
    "with open('Top_errors_for_each_chord_frame.txt', 'w') as outfile:\n",
    "    for j in range(len(chordnames_frame_all)):\n",
    "        ##Output as json format\n",
    "        #json.dump(chordnames_frame_all[j], outfile)\n",
    "        #json.dump(str(mistakes_frame_all[j]), outfile)\n",
    "        ##Output as txt format\n",
    "        outfile.write(chordnames_frame_all[j]+'\\n')\n",
    "        outfile.write(str(mistakes_frame_all[j])+'\\n')\n",
    "        print(chordnames_frame_all[j], mistakes_frame_all[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for chordname, mistakes in zip(chordnames_frame_all, mistakes_frame_all):\n",
    "    print(\"\\nreal chordname:\", chordname)\n",
    "    for mistake in mistakes:\n",
    "        difference = compute_chords_note_difference(chordname, mistake)\n",
    "        if difference:\n",
    "            print(\"\\tmistaken for:\", mistake, \"\\tdistance: \", difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "chordname = 'Ab/3'\n",
    "mistake = 'F:min'\n",
    "compute_chords_note_difference(chordname, mistake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_comparelabels_beat_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_foreachchord_frame_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
